{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebbea2e0-931d-4174-9fed-2f309348dff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch in /opt/conda/lib/python3.11/site-packages (8.12.0)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in /opt/conda/lib/python3.11/site-packages (from elasticsearch) (8.12.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /opt/conda/lib/python3.11/site-packages (from elastic-transport<9,>=8->elasticsearch) (2.0.7)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from elastic-transport<9,>=8->elasticsearch) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install elasticsearch\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60c457a0-f0d0-4734-be27-dcfc8d8e9d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.44      0.61        43\n",
      "    positive       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.44        43\n",
      "   macro avg       0.50      0.22      0.31        43\n",
      "weighted avg       1.00      0.44      0.61        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from elasticsearch import Elasticsearch\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType, StringType  # Import StringType here\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"My App\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load dataset\n",
    "data = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"./work/data.csv\")\n",
    "\n",
    "# Convert label column to numeric\n",
    "indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_index\")\n",
    "data = indexer.fit(data).transform(data)\n",
    "\n",
    "# Drop the original string label column\n",
    "data = data.drop(\"label\")\n",
    "\n",
    "# Rename the new numeric label column to \"label\"\n",
    "data = data.withColumnRenamed(\"label_index\", \"label\")\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "data = tokenizer.transform(data)\n",
    "\n",
    "# Create TF-IDF features\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "pipeline = Pipeline(stages=[hashingTF, idf])\n",
    "pipelineFit = pipeline.fit(data)\n",
    "data = pipelineFit.transform(data)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "(trainingData, testData) = data.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Train logistic regression model\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.01, probabilityCol=\"probability\")\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "# Extract the probability for the positive class from the \"probability\" column\n",
    "def get_positive_probability(probability):\n",
    "    return probability[1].item()\n",
    "\n",
    "get_positive_probability_udf = udf(get_positive_probability, DoubleType())\n",
    "\n",
    "predictions = predictions.withColumn(\"positive_probability\", get_positive_probability_udf(predictions[\"probability\"]))\n",
    "\n",
    "# Define a UDF to convert sentiment probability to label\n",
    "def get_sentiment_label(probability):\n",
    "    if probability >= 0.5:\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"negative\"\n",
    "\n",
    "sentiment_udf = udf(get_sentiment_label, StringType())\n",
    "\n",
    "# Add a column for sentiment label based on the positive probability\n",
    "predictions = predictions.withColumn(\"sentiment\", sentiment_udf(predictions[\"positive_probability\"]))\n",
    "\n",
    "# Connect to Elasticsearch\n",
    "es = Elasticsearch(['http://elasticsearch:9200'])\n",
    "\n",
    "# Check if the connection is successful\n",
    "if es.ping():\n",
    "    print(\"Connected to Elasticsearch\")\n",
    "else:\n",
    "    print(\"Could not connect to Elasticsearch\")\n",
    "\n",
    "# Convert Spark DataFrame to Pandas DataFrame\n",
    "predictions_pandas = predictions.select(\"id\", \"sentiment\").toPandas()\n",
    "\n",
    "# Save results to Elasticsearch\n",
    "for row in predictions_pandas.itertuples():\n",
    "    es.index(index='sentiment_analysis_index', body={'sentiment': row.sentiment, 'id': row.id})\n",
    "\n",
    "\n",
    "# Evaluate model\n",
    "pred = [1 if sentiment == 'positive' else 0 for sentiment in predictions_pandas['sentiment']]\n",
    "actual = [1 if label == 'pos' else 0 for label in testData.select('label').collect()]\n",
    "print(classification_report(actual, pred, target_names=['negative', 'positive']))\n",
    "\n",
    "# Stop SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4649a61b-c711-4c2c-9d8a-2231e1858103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b6200c-fce3-49db-8ece-f75608480703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
